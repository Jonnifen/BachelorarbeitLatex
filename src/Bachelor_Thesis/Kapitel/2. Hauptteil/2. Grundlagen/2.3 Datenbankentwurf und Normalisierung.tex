\subsection{Datenbankentwurf und Normalisierung}
\label{subsec:datenbankentwurf-und-normalisierung}
%------------------------------------------------------------------------------------------------------
Datenbanken sind strukturierte Zusammenstellungen von Daten, die elektronisch gespeichert und verwaltet werden.
Ihr Hauptziel ist es, große Datenmengen strukturiert zu speichern, den Zugriff zu optimieren und die Integrität der Daten zu gewährleisten.
Datenbanken haben im Vergleich zu anderen Dateisystemen Mechanismen, die mehreren Benutzern die parallele Nutzung ermöglichten,
sowie redundante Datenhaltung vermeiden und die effiziente Abfragen über spezielle Sprachen wie die \ac{SQL} ermöglichen.\cite*[6]{Fuchs2021}

In der folgen werden die Hauptanforderungen an Datenbanken bzw. Datenbankmanagementsysteme kurz zusammengefasst:  \cite*[7]{Herrmann2018},\cite*[6]{Fuchs2021}
\begin{itemize}
\item Datenunabhängigkeit: Speicherung unabhängig von Programmen und Plattformen
\item
Benutzerfreundlichkeit: Einfache Sprachen und grafische Oberflächen
\item
Mehrfachzugriff: Gleichzeitiger Zugriff für autorisierte Benutzer
\item
Flexibilität: Wahlfreier Zugriff und fortlaufende Verarbeitung
\item
Effizienz: Kurze Zeiten für Abfragen, Änderungen und Ergänzungen
\item
Datenschutz: Zugriff nach Benutzergruppen beschränkt
\item
Datensicherheit: Schutz vor Fehlern und Ausfällen
\item
Datenintegrität: Vollständige, korrekte und widerspruchsfreie Speicherung
\item
Redundanzfreiheit: Daten nur einmal speichern, Redundanz vermeiden
\end{itemize}



%------------------------------------------------------------------------------------------------------
\subsubsection{Datenbankstruktur}
%------------------------------------------------------------------------------------------------------
Die Struktur der Datenbank legt fest, wie das Datenbanksystem organisiert ist und wie die Datenelemente angeordnet sind.
Das Grundprinzip relationaler Datenbanken sind im Grunde Tabellen und die Beziehungen zwischen diesen.
Die Hauptbestandteile sind: \cite*[35]{Gadatsch2019}

\begin{itemize}
\item Tabellen – das grundlegende Element, welches Daten in Zeilen (Tupeln) und Spalten (Attributen) strukturiert.
\item Ein Datensatz in einer Tabelle wird durch Primärschlüssel (Primary Keys) eindeutig identifiziert.
\item Schlüssel aus anderen Tabellen (Foreign Keys)  Tabellenverknüpfung, um die referenzielle Integrität zu gewährleisten.
\item Indizes: Datenstrukturen, die das Beschleunigen von Abfragen ermöglichen.
\item Views: sie sind virtuelle Tabellen und beruhen auf den Ergebnissen von Abfragen.
\item Constraints: Vorgaben zur Gewährleistung der Datenintegrität (z.B. Wertebereiche, Pflichtfelder oder Dopplungen).
\end{itemize}
%------------------------------------------------------------------------------------------------------
\subsubsection{Datenintegrität und Normalisierung}
%------------------------------------------------------------------------------------------------------
Ein methodischer Ansatz zur Reduzierung von Redundanzen und Anomalien ist die Normalisierung.
Der Prozess erfolgt schrittweise durch die Normalformen, die durch Indizes (1NF, 2NF, 3NF, BCNF) definiert sind.
Alle Normalformen haben spezifische Arten von Datenanomalien zum Ziel: \cite*[38-41]{Gadatsch2019}

\begin{itemize}

\item 1. Normalform (1NF): Beseitigung mehrfacher Werte innerhalb einer Zelle.
\item 2. Normalform (2NF): Beseitigung partieller Abhängigkeiten.
\item 3. Normalform (3NF): Beseitigung transitiver Abhängigkeiten.

\end{itemize}

Die Gewährleistung, dass Daten korrekt, konsistent und vollständig sind,
fällt unter das Konzept der Datenintegrität.
Sie wird erzielt durch: \cite*[38-41]{Gadatsch2019}

\begin{itemize}
\item
Entity-Integrität (eindeutige Primärschlüssel).
\item
Referentielle Integrität (gültige Fremdschlüsselverweise).

\item Domänenintegrität (gültige Wertebereiche und Datentypen).
\item Entity-Integrität (eindeutige Primärschlüssel).
\item Referentielle Integrität (gültige Fremdschlüsselverweise).
\item Integrität der Domäne (gültige Wertebereiche und Datentypen).

\end{itemize}

%------------------------------------------------------------------------------------------------------
\subsubsection{Vorgehen zur Erstellung der Datenbank}
%------------------------------------------------------------------------------------------------------
Bei der Erstellung einer Datenbank sollte nach folgendem Schema vorgegangen werden.
Bei diesem Schema gilt es, sowohl technische als auch konzeptionelle Aspekte zu berücksichtigen: \cite*[9-11]{Herrmann2018}

\begin{enumerate}

\item
Anforderungsanalyse

Zuerst wird im Hinblick auf das Geschäftsumfeld bestimmt, welchen konkreten Zweck die Datenbank erfüllen soll.
Hierbei ist die Zweckbestimmung  entscheidend, da sie festlegt, welche Daten als relevant gelten.
Der Konzeptvorschlag, der das Projektziel definiert und die Vorgehensweise umreißt, ist das Ergebnis.
\begin{itemize}

\item
Festlegung der fachlichen und technischen Voraussetzungen.
\item
Bestimmung der relevanten Datenquellen und -formate.
\item
Definition von Integritäts- und Sicherheitsanforderungen.

\end{itemize}

\item
Konzeptionelles Datenmodell

Es soll das geschäftliche Umfeld betrachtet werden.
Die bestehende Objekte (z.B. Reports mit Materialnummer, Datum, Version), deren Attribute sowie die Beziehungen und Einschränkungen zwischen diesen Objekten.
Das Entity-Relationship-Modell (ERM) nach Chen oder das PrecisedERM (PERM) werden häufig zur Modellierung verwendet.
Der konzeptionelle Entwurf ist die Grundlage für die nächste Phase und dient als Diskussionsgrundlage.
\begin{itemize}

\item Die Entwicklung eines Entity-Relationship-Modells (ERM), das die reale Welt in Entitäten, Attribute und Beziehungen abbildet.
\item Die Einbeziehung von Kardinalitäten (1:1, 1:n, n:m).

\end{itemize}

\item
Logisches Datenmodell

Der konzeptionelle Entwurf wird in einen logischen Entwurf umgewandelt, der die fachlichen Konzepte in ein datenbanktechnisches Format überführt.
In der Regel kommt das Relationenmodell zum Einsatz, welches die Daten in Form von Tabellen organisiert.
Transformationsregeln garantieren, dass Beziehungen und Integritätsbedingungen richtig umgesetzt werden.
\begin{itemize}

\item Transformation des konzeptionellen Modells in ein relationales Schema.
\item Festlegung von Tabellen, Spalten (Attribute), Primärschlüsseln und Fremdschlüsseln.
\item Definition von Datentypen und Zellenkofigurationen (z.B. NOT NULL, UNIQUE, CHECK).
\end{itemize}

\item
Physisches Datenmodell

Eine physische Datenbankstruktur wird durch \ac{SQL} erstellt, basierend auf dem logischen Entwurf.
Die konkrete Festlegung von Tabellen, Indizes, Constraints usw. erfolgt dabei durch  Das System,
das wir implementiert haben, wird immer wieder getestet und zusammen mit den Nutzerinnen auf fachliche Richtigkeit überprüft.
\begin{itemize}

\item Realisierung des logischen Modells in einer spezifischen Datenbankmanagementsoftware (z.B. MySQL, Mariadb oder Microsoft SQL Server).er).
\item Die Verbesserung der Speicherstrukturen, der Indexierung und der Partitionierung.

\end{itemize}

\item
Implementierung und Prüfung

Nach der erfolgreichen Umsetzung wird das System vom Kunden gemäß einem vorher festgelegten Abnahmeplan freigegeben.
Ein Wartungsplan kümmert sich anschließend um die Betreuung, schult die Endbenutzer und überwacht die IT-Umgebung kontinuierlich.
\begin{itemize}

\item Den Aufbau der Tabellen und Relationen entsprechend dem Datenbankschema.

\item Die Testdaten implementieren.

\item Die Kontrolle der Funktionalität und Leistung.

\end{itemize}

\end{enumerate}

\subsubsection{Methoden zum Datenbankzugriff in Flask}
Direkte Verwendung von SQL mit sqlite3 oder mysql.connector

Die einfachste Form der Datenbankanbindung erfolgt über ein direktes Python-Modul für die jeweilige Datenbank (z. B. SQLite oder MySQL). Dabei werden SQL-Befehle manuell geschrieben und ausgeführt.

Diese Methode ist transparent, aber fehleranfälliger und erfordert Kenntnisse in SQ


Verwendung von Flask-SQLAlchemy (ORM)

Flask-SQLAlchemy ist eine der beliebtesten und professionellsten Methoden für Flask-Anwendungen.

Es basiert auf SQLAlchemy, einem mächtigen Object-Relational Mapper (ORM), der SQL-Tabellen als Python-Klassen abbildet.

Dadurch entfällt das manuelle Schreiben vieler SQL-Befehle.


SQLModel – moderne Alternative (von FastAPI inspiriert)

SQLModel (von Sebastián Ramírez, dem Autor von FastAPI) kombiniert Pydantic-Modelle mit SQLAlchemy ORM.

Dadurch entstehen typsichere Datenmodelle, die gleichzeitig als ORM und als Validierungsobjekte verwendet werden können.


Verwendung von Flask-Peewee

Peewee ist ein leichtgewichtiger ORM, der einfacher zu verwenden ist als SQLAlchemy.

Er eignet sich für kleinere Projekte mit geringem Datenbankumfang.


Zur persistenten Datenspeicherung wird das ORM-Framework \textit{Flask-SQLAlchemy} verwendet, das auf \textit{SQLAlchemy} basiert.
Es ermöglicht die objektorientierte Abbildung relationaler Datenbanken und vereinfacht den Zugriff auf Daten über Python-Klassen.
Dadurch wird eine saubere Trennung von Anwendungslogik und Datenzugriffsschicht erreicht.
